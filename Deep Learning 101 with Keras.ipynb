{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 101 - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.7129 - acc: 0.5230 - val_loss: 0.6622 - val_acc: 0.6400\n",
      "Epoch 2/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.6716 - acc: 0.6090 - val_loss: 0.6221 - val_acc: 0.6326\n",
      "Epoch 3/25\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.6326 - acc: 0.6590 - val_loss: 0.6472 - val_acc: 0.6616\n",
      "Epoch 4/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.5980 - acc: 0.6670 - val_loss: 0.5820 - val_acc: 0.6667\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.5822 - acc: 0.7090 - val_loss: 0.5460 - val_acc: 0.7275\n",
      "Epoch 6/25\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.5789 - acc: 0.7015 - val_loss: 0.5519 - val_acc: 0.7285\n",
      "Epoch 7/25\n",
      "125/125 [==============================] - 37s 292ms/step - loss: 0.5323 - acc: 0.7445 - val_loss: 0.4813 - val_acc: 0.7753\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.5446 - acc: 0.7335 - val_loss: 0.5692 - val_acc: 0.7071\n",
      "Epoch 9/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.5188 - acc: 0.7505 - val_loss: 0.5354 - val_acc: 0.7551\n",
      "Epoch 10/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.5031 - acc: 0.7625 - val_loss: 0.5181 - val_acc: 0.7725\n",
      "Epoch 11/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.5010 - acc: 0.7730 - val_loss: 0.5152 - val_acc: 0.7437\n",
      "Epoch 12/25\n",
      "125/125 [==============================] - 37s 294ms/step - loss: 0.4882 - acc: 0.7790 - val_loss: 0.5224 - val_acc: 0.7500\n",
      "Epoch 13/25\n",
      "125/125 [==============================] - 37s 292ms/step - loss: 0.4977 - acc: 0.7780 - val_loss: 0.5029 - val_acc: 0.7588\n",
      "Epoch 14/25\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.4743 - acc: 0.7930 - val_loss: 0.5632 - val_acc: 0.7551\n",
      "Epoch 15/25\n",
      "125/125 [==============================] - 37s 298ms/step - loss: 0.4456 - acc: 0.7895 - val_loss: 0.5479 - val_acc: 0.7137\n",
      "Epoch 16/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.4707 - acc: 0.7945 - val_loss: 0.4917 - val_acc: 0.7765\n",
      "Epoch 17/25\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.4605 - acc: 0.7920 - val_loss: 0.4610 - val_acc: 0.7803\n",
      "Epoch 18/25\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.4339 - acc: 0.8025 - val_loss: 0.5403 - val_acc: 0.7475\n",
      "Epoch 19/25\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.4482 - acc: 0.8035 - val_loss: 0.4604 - val_acc: 0.7715\n",
      "Epoch 20/25\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.4332 - acc: 0.8060 - val_loss: 0.5132 - val_acc: 0.7500\n",
      "Epoch 21/25\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.4314 - acc: 0.8045 - val_loss: 0.5041 - val_acc: 0.7513\n",
      "Epoch 22/25\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.4271 - acc: 0.8110 - val_loss: 0.5924 - val_acc: 0.7475\n",
      "Epoch 23/25\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.4319 - acc: 0.8120 - val_loss: 0.5132 - val_acc: 0.7715\n",
      "Epoch 24/25\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.4217 - acc: 0.8210 - val_loss: 0.4965 - val_acc: 0.7790\n",
      "Epoch 25/25\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.4202 - acc: 0.8350 - val_loss: 0.4630 - val_acc: 0.7863\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "# Existem dois tipos de modelos, porém o Sequencial é o mais comum.\n",
    "\n",
    "#Aqui adicionamos uma camada convulacional à rede. Declaramos que ela deve extrair 32 filtros\n",
    "#e que os kernels serão uma matriz 3x3.\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "\n",
    "# Em seguida, uma camada de neurônios de ativação, RELU é um tipo de função de ativação.\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#A camada de Max Pooling é adicionada e tem como finalidade destacar apenas os filtros gerados \n",
    "#com maior valor de ativação. Ex.: Detectar Features mais relevantes\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Adicionamos mais camadas Convulacionais, de Ativação e de Max Pooling\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Neste ponto, nosso modelo tem como output um mapa 3D de features! (Traços, Bordas, Retas) - Pequenas partes da imagem que \n",
    "#são comuns à cada classe.\n",
    "\n",
    "# Por fim, utilizamos a função Flatten, para converter nosso mapa 3D de Features em um Vetor de 1 Dimensão\n",
    "# (Pense em um array)\n",
    "# Adicionamos também as camadas Dense (Totalmente Conectadas) e mais funções de ativação ao modelo.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#Para cada tipo de problema, existe uma loss function, uma função de otimização e as métricas mais adequadas.\n",
    "#Esses elementos são parâmetros para a compilação do modelo\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Após definir o modelo da rede e compilar, criamos instâncias de geradores de dados \n",
    "#(Elementos que vão ler cada uma das images de imput)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('dog_cat_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = train_generator.class_indices\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load model\n",
    "model = load_model(\"dog_cat_model.h5\")\n",
    "\n",
    "# image path\n",
    "img_path_1 = 'test/tchalla1.jpg'    # cat\n",
    "img_path_2 = 'test/dog1.jpg'    # dog\n",
    "\n",
    "# load a single image\n",
    "new_image_1 = load_image(img_path_1)\n",
    "new_image_2 = load_image(img_path_2)\n",
    "\n",
    "\n",
    "# check prediction\n",
    "pred_1 = model.predict(new_image_1)\n",
    "pred_2 = model.predict(new_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.195776]]\n",
      "[[0.9263898]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_1)\n",
    "print(pred_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "if pred_1[0][0] >= 0.5:\n",
    "    result_1 = 'dog'\n",
    "else:\n",
    "    result_1 = 'cat'\n",
    "\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "if pred_2[0][0] >= 0.5:\n",
    "    result_2 = 'dog'\n",
    "else:\n",
    "    result_2 = 'cat'\n",
    "\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]] [[0.195776]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(new_image_1)\n",
    "prob = model.predict_proba(new_image_1)\n",
    "print(preds, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
